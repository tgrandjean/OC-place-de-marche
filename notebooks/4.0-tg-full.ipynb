{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import cv2\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import scikitplot as skplt\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.6)\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 93680329\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('../data/raw/'):\n",
    "    if len(filenames) == 1:\n",
    "        df = pd.read_csv(os.path.join(dirname, filenames[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['path'] = df['image'].apply(lambda x: os.path.join('../data/raw/Images/', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = [\n",
    "    'uniq_id',\n",
    "    'crawl_timestamp',\n",
    "    'product_url',\n",
    "    'pid',\n",
    "    'discounted_price',\n",
    "    'is_FK_Advantage_product',\n",
    "    'product_rating',\n",
    "    'overall_rating',\n",
    "    'product_specifications',\n",
    "    'brand',\n",
    "    \n",
    "]\n",
    "df.drop(columns=col_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def extract_level(tree_str, level=-1, strict=False):\n",
    "    \"\"\"return a specific level from product_category_tree.\n",
    "    tips: specify a negative index to access latest part of the tree.\n",
    "    \"\"\"\n",
    "    tree_str = eval(tree_str)[0]\n",
    "    levels = tree_str.split('>>')\n",
    "    levels = list(map(lambda x: x.strip(), levels))\n",
    "    if strict:\n",
    "        return levels[level]\n",
    "    else:\n",
    "        try:\n",
    "            return levels[level]\n",
    "        except IndexError:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['product_category_tree'].apply(extract_level, level=1)\n",
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_category_tree'].apply(extract_level, level=0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet')\n",
    "model = keras.Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)\n",
    "image_224 = np.array([np.array(Image.open(x).resize((224, 224))) for x in df['path']])\n",
    "features = model.predict(image_224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['description'].to_list()\n",
    "\n",
    "punctuation = re.compile(r'[.,;!?:()/&-]+')\n",
    "sentences = list(map(str.lower, sentences))\n",
    "sentences = [re.sub(punctuation, ' ', x) for x in sentences]\n",
    "\n",
    "# remove numeric data\n",
    "numeric = re.compile(r'\\d+')\n",
    "sentences = [re.sub(numeric, '', x) for x in sentences]\n",
    "tokens = list(map(nltk.word_tokenize, sentences))\n",
    "\n",
    "filtered = list()\n",
    "for sentence in tokens:\n",
    "    sentence_ = list()\n",
    "    for word in sentence:\n",
    "        if word not in nltk.corpus.stopwords.words('english'):\n",
    "            sentence_.append(word)\n",
    "    filtered.append(sentence_)\n",
    "tokens = filtered\n",
    "\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "token_stem = list()\n",
    "for desc in tokens:\n",
    "    desc_ = list()\n",
    "    for token in desc:\n",
    "        desc_.append(stemmer.stem(token))\n",
    "    token_stem.append(desc_)\n",
    "tokens = token_stem\n",
    "\n",
    "bag_of_words = []\n",
    "\n",
    "for tk in tokens:\n",
    "    bag_of_words.append(Counter(tk))\n",
    "\n",
    "df_bofw = pd.DataFrame.from_records(bag_of_words)\n",
    "df_bofw.fillna(0, inplace=True)\n",
    "\n",
    "# as frequencies\n",
    "df_bofw = df_bofw.div(df_bofw.sum(axis=1), axis=0)\n",
    "\n",
    "too_frequent = df_bofw.sum(axis=0)[df_bofw.sum(axis=0) > 10].index\n",
    "too_rare = df_bofw.sum(axis=0)[df_bofw.sum(axis=0) < 2e-2].index\n",
    "\n",
    "for tk in list(too_frequent) + list(too_rare):\n",
    "    df_bofw.drop(tk, axis=1, inplace=True)\n",
    "    \n",
    "print(df_bofw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_features = np.concatenate((features, df_bofw), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(full_features)\n",
    "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "skplt.decomposition.plot_pca_component_variance(pca, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_res = PCA(n_components=1000).fit_transform(full_features)\n",
    "tsne_res = TSNE(n_components=2, perplexity=30, \n",
    "                learning_rate=10, n_iter=2500).fit_transform(pca_res)\n",
    "\n",
    "tsne_res = pd.DataFrame(tsne_res)\n",
    "tsne_res['label'] = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = tsne_res.groupby('label').mean()\n",
    "centers.reset_index(drop=False, inplace=True)\n",
    "\n",
    "_, ax = plt.subplots(1, figsize=(24, 18))\n",
    "palette = sns.color_palette(None, centers.shape[0])\n",
    "for i, center in enumerate(centers['label']):\n",
    "    if tsne_res.groupby('label').count().loc[center, 0] > 10:\n",
    "        ax.scatter(x=tsne_res.loc[tsne_res['label'] == center, 0],\n",
    "           y=tsne_res.loc[tsne_res['label'] == center, 1],\n",
    "           color=palette[i]\n",
    "          )\n",
    "        \n",
    "        ax.annotate(center, centers.set_index('label').loc[center, :].values,\n",
    "                    color=palette[i]\n",
    "                   )\n",
    "# plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exemple basique pour la présentation finale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Ay, madam, it is common.\"\n",
    "test_2 = \"\"\" Seems, madam ? Nay, it is. I know not ‘seems’.\n",
    "   ‘Tis not alone my inky cloak, good mother, \n",
    "   Nor customary suits of solemn black,\n",
    "   Nor windy suspiration of forc’d breath,\n",
    "   No, nor the fruitful river in the eye,\n",
    "   Nor the dejected haviour of the visage, \n",
    "   Together with all forms, moods, shapes of grief,\n",
    "   That can denote me truly. These indeed seem,\n",
    "   For they are actions that a man might play ;\n",
    "   But I have that within which passes show,\n",
    "   These but the trappings and the suits of woe.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.lower()\n",
    "test_2 = test_2.lower()\n",
    "\n",
    "test, test_2 = test.replace('\\n', ' '), test_2.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.tokenize.word_tokenize(test)\n",
    "nltk.tokenize.word_tokenize(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = re.compile(r'[.,;!?:()/&-\\\\‘\\\\’]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = re.sub(punctuation, ' ', test)\n",
    "test_2 = re.sub(punctuation, ' ', test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.tokenize.word_tokenize(test.lower())\n",
    "tokens_2 = nltk.tokenize.word_tokenize(test_2.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = list()\n",
    "for tk in tokens:\n",
    "    if tk not in nltk.corpus.stopwords.words('english'):\n",
    "        filtered.append(tk)\n",
    "tokens = filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_2 = list()\n",
    "for tk in tokens_2:\n",
    "    if tk not in nltk.corpus.stopwords.words('english'):\n",
    "        filtered_2.append(tk)\n",
    "tokens_2 = filtered_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_2 = [nltk.stem.PorterStemmer().stem(x) for x in tokens_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bofw = pd.DataFrame.from_records([Counter(tokens_2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bofw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.stem.PorterStemmer().stem(\"engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "place-de-marche",
   "language": "python",
   "name": "place-de-marche"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
