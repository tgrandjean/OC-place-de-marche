{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place de marché\n",
    "==============\n",
    "\n",
    "![logo](../reports/figures/logo.png)\n",
    "\n",
    "\n",
    "### Votre mission\n",
    "Votre mission est de **réaliser une première étude de faisabilité d'un moteur de classification** d'articles basé sur une image et une description pour l'automatisation de l'attribution de la catégorie de l'article.\n",
    "\n",
    "Pour ce faire, vous allez **évaluer la possibilité d'extraire des données depuis l'API Amazon** en **prenant connaissance de la documentation** et en **écrivant la requête** qui vous permettrait d'extraire des données supplémentaires. Vous vous assurerez ainsi que vous pourrez bien disposer de plus de données et diversifier les sources de données pour éviter les biais pour votre moteur de classification.\n",
    "\n",
    "Ensuite, vous **analyserez le jeu de données** déjà constitué en **réalisant un prétraitement** des images et des descriptions des produits, une **réduction de dimension**, puis un **clustering**. Les résultats du clustering seront présentés sous la forme d’une représentation en deux dimensions à déterminer, qui ’illustrera le fait que les caractéristiques extraites permettent de regrouper des produits de même catégorie.\n",
    "\n",
    "La représentation graphique vous aidera à convaincre Linda que cette approche de modélisation permettra bien de regrouper des produits de même catégorie.\n",
    "\n",
    "### Contraintes\n",
    "\n",
    "Linda vous a communiqué les contraintes suivantes :\n",
    "\n",
    "   * Limiter le nombre d’articles pris par l’API (par exemple : 1000 lignes) et filtrer sur un unique type d’article (par exemple un type d’article peu présent dans votre échantillon de données actuelles).\n",
    "   * Afin d’extraire les features, mettre en œuvre a minima un algorithme de type SIFT / ORB / SURF.\n",
    "   * Un algorithme de type CNN Transfer Learning peut éventuellement être utilisé en complément, s’il peut apporter un éclairage supplémentaire à la démonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.6)\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 93680329\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('../data/raw/'):\n",
    "    if len(filenames) == 1:\n",
    "        df = pd.read_csv(os.path.join(dirname, filenames[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['path'] = df['image'].apply(lambda x: os.path.join('../data/raw/Images/', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = [\n",
    "    'uniq_id',\n",
    "    'crawl_timestamp',\n",
    "    'product_url',\n",
    "    'pid',\n",
    "    'discounted_price',\n",
    "    'is_FK_Advantage_product',\n",
    "    'product_rating',\n",
    "    'overall_rating',\n",
    "    'product_specifications',\n",
    "    'brand',\n",
    "    \n",
    "]\n",
    "df.drop(columns=col_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_level(tree_str, level=-1, strict=False):\n",
    "    \"\"\"return a specific level from product_category_tree.\n",
    "    tips: specify a negative index to access latest part of the tree.\n",
    "    \"\"\"\n",
    "    tree_str = eval(tree_str)[0]\n",
    "    levels = tree_str.split('>>')\n",
    "    levels = list(map(lambda x: x.strip(), levels))\n",
    "    if strict:\n",
    "        return levels[level]\n",
    "    else:\n",
    "        try:\n",
    "            return levels[level]\n",
    "        except IndexError:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère le premier niveau de l'arbre des catégories comme label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['product_category_tree'].apply(extract_level, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 comme extracteur de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins import projector\n",
    "\n",
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_224 = np.array([np.array(Image.open(x).resize((224, 224))) for x in df['path']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_224.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.predict(image_224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=9, learning_rate=10, n_iter=2500)\n",
    "tsne_res = tsne.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_res = pd.DataFrame(tsne_res)\n",
    "tsne_res['label'] = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = tsne_res.groupby('label').mean()\n",
    "centers.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, figsize=(24, 18))\n",
    "palette = sns.color_palette(None, centers.shape[0])\n",
    "for i, center in enumerate(centers['label']):\n",
    "    if tsne_res.groupby('label').count().loc[center, 0] > 10:\n",
    "        ax.scatter(x=tsne_res.loc[tsne_res['label'] == center, 0],\n",
    "           y=tsne_res.loc[tsne_res['label'] == center, 1],\n",
    "           color=palette[i]\n",
    "          )\n",
    "        \n",
    "        ax.annotate(center, centers.set_index('label').loc[center, :].values,\n",
    "                    color=palette[i]\n",
    "                   )\n",
    "# plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(255 - np.array(image_224[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(255 - np.array(image_224[45]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(np.array(image_224[45]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation dans TensorBoard\n",
    "\n",
    "**warning** Une fois le comportement de TensorFlow v2 désactivé, Keras va lever une exception!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def images_to_sprite(data):\n",
    "        \"\"\"Creates the sprite image along with any necessary padding\n",
    "\n",
    "        Args:\n",
    "          data: NxHxW[x3] tensor containing the images.\n",
    "\n",
    "        Returns:\n",
    "          data: Properly shaped HxWx3 image with any necessary padding.\n",
    "        \"\"\"\n",
    "        if len(data.shape) == 3:\n",
    "            data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "        data = data.astype(np.float32)\n",
    "        min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "        data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n",
    "        max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "        data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n",
    "        # Inverting the colors seems to look better for MNIST\n",
    "        #data = 1 - data\n",
    "\n",
    "        n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "        padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "                (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "        data = np.pad(data, padding, mode='constant',\n",
    "                constant_values=0)\n",
    "        # Tile the individual thumbnails into an image.\n",
    "        data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "                + tuple(range(4, data.ndim + 1)))\n",
    "        data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "        data = (data * 255).astype(np.uint8)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(images_to_sprite(image_224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data = tf.Variable(features, name='features')\n",
    "\n",
    "LOG_DIR = '../reports/tf/sessions/resnet/'\n",
    "\n",
    "sprite = images_to_sprite(image_224)\n",
    "cv2.imwrite(os.path.join(LOG_DIR, 'sprite_4_classes.png'), sprite)\n",
    "\n",
    "metadata = 'df_labels.tsv'\n",
    "\n",
    "# df[['image', 'label']].to_csv(os.path.join(LOG_DIR, metadata), index=False, header=False)\n",
    "df['label'].to_csv(os.path.join(LOG_DIR, metadata), index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     saver = tf.train.Saver([tf_data])\n",
    "#     sess.run(tf_data.initializer)\n",
    "#     saver.save(sess, os.path.join(LOG_DIR, 'tf_data.ckpt'))\n",
    "#     config = projector.ProjectorConfig()\n",
    "    \n",
    "#     embedding = config.embeddings.add()\n",
    "#     embedding.tensor_name = tf_data.name\n",
    "    \n",
    "#     embedding.metadata_path = metadata\n",
    "    \n",
    "#     embedding.sprite.image_path = 'sprite_4_classes.png'\n",
    "#     embedding.sprite.single_image_dim.extend([image_224.shape[1], image_224.shape[1]])\n",
    "\n",
    "#     projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), \n",
    "#                                    config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "place-de-marche",
   "language": "python",
   "name": "place-de-marche"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
